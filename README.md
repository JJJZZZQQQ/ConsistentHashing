# ConsistentHashing

## 简介
背景：传统Hash算法，直接取模运算，当发生rehash是灾难级别的，可能造成系统雪崩


而一致性哈希算法的出现就是为了解决这个问题，它是分布式系统中非常常见的算法，基于一致性哈希算法设计的分片系统，
系统数据分散较为平均，扩容缩容时对系统影响很小。


一致性Hash算法使用Hash环，每一个数据都**顺时针找到对应的服务器**，这样不管是缩容还是扩容，都只有环上的**一部分数据会被影响**。

![image-20220604195242831](http://img.jjjzzzqqq.top/image-20220604195242831.png)


但是这样还是有问题：

* 正常情况下，有可能出现冷热数据的现象，导致部分节点负载很大，影响集群的稳定性
* 缩容扩容之后，由于添加或者删除了节点，此时节点分布不均匀，导致数据分散不平衡，也会有影响集群的稳定性

为了解决这两个问题，引入了虚拟节点，**一个真实节点对应多个虚拟节点**，当一个真实节点挂掉时，多个虚拟节点同时挂掉，每一个虚拟节点会影响Hash环的一部分数据，这样**影响的总量没变**，但是却变得平衡了，从而解决了不平衡的问题。

<img src="http://img.jjjzzzqqq.top/image-20220111221741734.png" alt="image-20220111221741734" style="zoom:50%;" />

添加完虚拟节点之后，系统数据分布如下

![image-20220601105746733](http://img.jjjzzzqqq.top/image-20220601105746733.png)

## 实现思路
我们先来看一下实现分片的两个经典场景，该仓库会通过客户端分片的方式，完成分片的功能。

### 客户端分片
将系统分为多个分片，由客户端进行请求连接的分发，重定向等操作。

类似的经典实现有Redis Cluster，
当我们请求的数据不在对应节点的时候，Redis就会返回Moved错误来提醒Redis 客户端进行重定向的操作。

### 服务端分片
我们直接将分片这个功能内置到我们的自研中间件中，客户端每次请求随机的节点，将这个被请求的节点视为coordinate node，该节点会通过一致性哈希算法进行计算，
然后重定向到集群对应的节点，真实节点返回数据给coordinate node，coordinate node返回数据给客户端。

类似的经典实现有Elasticsearch。
* 客户端发送请求到一个 coordinate node 。
* 协调节点将搜索请求转发到所有的 shard 对应的 primary shard 或 replica shard ，都可以。
* query phase：每个 shard 将自己的搜索结果（其实就是一些 doc id ）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。
* fetch phase：接着由协调节点根据 doc id 去各个节点上拉取实际的 document 数据，最终返回给客户端。



